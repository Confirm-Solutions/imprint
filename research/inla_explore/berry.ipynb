{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import inla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_gauss_rule(N, a, b):\n",
    "    A = np.log(a)\n",
    "    B = np.log(b)\n",
    "    p, w = inla.gauss_rule(N, a=A, b=B)\n",
    "    pexp = np.exp(p)\n",
    "    wexp = np.exp(p) * w\n",
    "    return (pexp, wexp)\n",
    "\n",
    "a = 1e-8\n",
    "b = 1e3\n",
    "pexp, wexp = log_gauss_rule(90, a, b)\n",
    "alpha = 0.0005\n",
    "beta = 0.000005\n",
    "f = scipy.stats.invgamma.pdf(pexp, alpha, scale=beta)\n",
    "exact = scipy.stats.invgamma.cdf(b, alpha, scale=beta) - scipy.stats.invgamma.cdf(a, alpha, scale=beta)\n",
    "est = np.sum(f * wexp)\n",
    "plt.plot(np.log(pexp) / np.log(10), f)\n",
    "plt.xlabel('$log_{10}\\sigma^2$')\n",
    "plt.ylabel('$PDF$')\n",
    "plt.show()\n",
    "print('exact CDF: ', exact),\n",
    "print('numerical integration CDF: ', est)\n",
    "print('error: ', est - exact)\n",
    "sigma2_rule = (pexp, wexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model and simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match with the INLA notation, the $\\theta$ parameter for Berry et al 2013 is called $x$ here. Also, Berry uses:\n",
    "\\begin{equation}\n",
    "\\tilde{x} = logit(p) - logit(p_1)\n",
    "\\end{equation}\n",
    "whereas we use:\n",
    "\\begin{equation}\n",
    "x = logit(p) = \\tilde{x} + logit(p_1)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = np.full(4, 0.1) # rate of response below this is the null hypothesis\n",
    "p1 = np.full(4, 0.3) # rate of response above this is the alternative hypothesis.\n",
    "# rate of response > p0 and < p1 is gray area.\n",
    "p0_x = scipy.special.logit(p0)\n",
    "\n",
    "pmid = (p0 + p1) / 2\n",
    "pmid_x = scipy.special.logit(pmid)\n",
    "\n",
    " # final evaluation criterion \n",
    " # accept the alternative hypo if Pr(p[i] > p0|data) > pfinal_thresh[i]\n",
    "pfinal_thresh = np.full(4, 0.85)\n",
    "\n",
    "# early stopping criterion\n",
    "pmid_accept = 0.9\n",
    "pmid_fail = 0.05\n",
    "\n",
    "null_x_berry = np.log(p0 / (1 - p0)) - np.log(p1 / (1 - p1))\n",
    "null_x = np.log(p0 / (1 - p0))\n",
    "prior_mu_mean = null_x[0]\n",
    "\n",
    "def berry_prior(theta):\n",
    "    mu = theta[..., 0]\n",
    "    mu_prior = scipy.stats.norm.logpdf(mu, prior_mu_mean, 100)\n",
    "\n",
    "    sigma2 = theta[..., 1]\n",
    "    alpha = 0.0005\n",
    "    beta = 0.000005\n",
    "    sigma2_prior = scipy.stats.invgamma.logpdf(sigma2, alpha, scale=beta)\n",
    "    return mu_prior + sigma2_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I got this data by deconstructing the graphs in in Figure 1 of Berry et al 2013.\n",
    "n_i = np.array([[i] * 4 for i in [10,15,20,25,30,35]])\n",
    "y_i = np.array([[1, 6, 3, 3], [3, 8, 5, 4], [6,9,7,5], [7,10,8,7], [8,10,9,8], [11, 11, 10, 9]])\n",
    "data = np.stack((y_i, n_i), axis=2)\n",
    "\n",
    "model = inla.binomial_hierarchical()\n",
    "model.log_prior = berry_prior\n",
    "\n",
    "mu_rule = inla.gauss_rule(201, -5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_i / n_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "post_theta, report = inla.calc_posterior_theta(model, data, (mu_rule, sigma2_rule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_field(logpost_theta_data, field, levels=None, label=None):\n",
    "    MM = logpost_theta_data[\"theta_grid\"][:,:,0]\n",
    "    SS = logpost_theta_data[\"theta_grid\"][:,:,1]\n",
    "    log_sigma_grid = np.log10(SS)\n",
    "    cntf = plt.contourf(\n",
    "        MM, log_sigma_grid, field, levels=levels, extend=\"both\"\n",
    "    )\n",
    "    plt.contour(\n",
    "        MM,\n",
    "        log_sigma_grid,\n",
    "        field,\n",
    "        colors=\"k\",\n",
    "        linestyles=\"-\",\n",
    "        linewidths=0.5,\n",
    "        levels=levels,\n",
    "        extend=\"both\",\n",
    "    )\n",
    "    cbar = plt.colorbar(cntf)\n",
    "    if label is not None:\n",
    "        cbar.set_label(None)\n",
    "    plt.xlabel(\"$\\mu$\")\n",
    "    plt.ylabel(\"$\\log_{10} (\\sigma^2)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$1.0 = \\sum_i f(x_i) w_i$$\n",
    "\n",
    "\"CDF\" is:\n",
    "* $f(x_i)$\n",
    "\n",
    "\"cumulative prob\" is:\n",
    "* $f(x_i) * w_i$\n",
    "\n",
    "the cdf would be... \n",
    "$$ F(x_j) = \\sum_{i < j} f(x_i) w_i$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.linspace(-8, 5, 31)\n",
    "field = np.log10(post_theta[0]).reshape(report['theta_grid'].shape[:2])\n",
    "field[np.isnan(field) | np.isinf(field)] = -20\n",
    "plt.title(f\"Posterior PDF from INLA\")\n",
    "plot_field(report, field, levels=levels, label=\"$\\log_{10}$ (density)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_volume = mu_rule[1][:, None] * sigma2_rule[1][None, :]\n",
    "cell_volume = scipy.ndimage.gaussian_filter(cell_volume, 1.0)\n",
    "levels = np.linspace(-9, -2, 31)\n",
    "\n",
    "field = np.log10(post_theta[0] * cell_volume).reshape(report['theta_grid'].shape[:2])\n",
    "field[np.isnan(field) | np.isinf(field)] = -20\n",
    "plt.title(f\"PDF*(quadrature weights)\")\n",
    "plot_field(report, field, levels=levels, label=\"$\\log_{10}$ (density)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure1_plot(data, post_theta, report):\n",
    "    mu_post, sigma_post = inla.calc_posterior_x(post_theta, report)\n",
    "\n",
    "    # expit(mu_post) is the posterior estimate of the mean probability.\n",
    "    p_post = scipy.special.expit(mu_post)\n",
    "\n",
    "    # two sigma confidence intervals transformed from logit to probability space.\n",
    "    cilow = scipy.special.expit(mu_post - 2 * sigma_post)\n",
    "    cihigh = scipy.special.expit(mu_post + 2 * sigma_post)\n",
    "\n",
    "    y = data[:, :, 0]\n",
    "    n = data[:, :, 1]\n",
    "\n",
    "    # The simple ratio of success to samples. Binomial \"p\".\n",
    "    raw_ratio = y / n\n",
    "    p_success = np.empty_like(mu_post)\n",
    "\n",
    "    # early stopping criterion\n",
    "    p_success[:5] = 1.0 - scipy.stats.norm.cdf(pmid_x, mu_post[:5], sigma_post[:5])\n",
    "    # final success criterion\n",
    "    p_success[5] = 1.0 - scipy.stats.norm.cdf(p0_x, mu_post[5], sigma_post[5])\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    outergs = fig.add_gridspec(2, 3, hspace=0.3)\n",
    "    for i in range(data.shape[0]):\n",
    "\n",
    "        innergs = outergs[i].subgridspec(\n",
    "            2, 1, wspace=0, hspace=0, height_ratios=[0.7, 0.3]\n",
    "        )\n",
    "\n",
    "        plt.subplot(innergs[0])\n",
    "        plt.plot(np.arange(4), raw_ratio[i], \"kx\")\n",
    "        plt.plot(np.arange(4), p_post[i], \"ko\", mfc=\"none\")\n",
    "        plt.plot(np.arange(4), p_success[i], \"k \", marker=(8, 2, 0))\n",
    "\n",
    "        plt.vlines(np.arange(4), cilow[i], cihigh[i], color=\"k\", linewidth=1.0)\n",
    "\n",
    "        if i < 5:\n",
    "            plt.title(f\"Interim Analysis {i+1}\")\n",
    "            plt.hlines([pmid_fail, pmid_accept], -1, 4, colors=[\"k\"], linestyles=[\"--\"])\n",
    "            plt.text(-0.1, 0.91, \"Early Success\", fontsize=7)\n",
    "            plt.text(2.4, 0.06, \"Early Futility\", fontsize=7)\n",
    "        else:\n",
    "            plt.title(\"Final Analysis\")\n",
    "            plt.hlines([pfinal_thresh[0]], -1, 4, colors=[\"k\"], linestyles=[\"--\"])\n",
    "            plt.text(-0.1, 0.86, \"Final Success\", fontsize=7)\n",
    "\n",
    "        plt.xlim([-0.3, 3.3])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.yticks(np.linspace(0.0, 1.0, 6))\n",
    "        plt.xlabel(\"Group\")\n",
    "        plt.ylabel(\"Probability\")\n",
    "\n",
    "        plt.subplot(innergs[1])\n",
    "        plt.bar(\n",
    "            [0, 1, 2, 3],\n",
    "            n[i],\n",
    "            tick_label=[str(i) for i in range(4)],\n",
    "            color=(0.6, 0.6, 0.6, 1.0),\n",
    "            edgecolor=\"k\",\n",
    "            zorder=0,\n",
    "        )\n",
    "        plt.bar(\n",
    "            [0, 1, 2, 3],\n",
    "            y[i],\n",
    "            color=(0.6, 0.6, 0.6, 1.0),\n",
    "            hatch=\"////\",\n",
    "            edgecolor=\"w\",\n",
    "            lw=1.0,\n",
    "            zorder=1,\n",
    "        )\n",
    "        #         # draw hatch\n",
    "        # ax1.bar(range(1, 5), range(1, 5), color='none', edgecolor='red', hatch=\"/\", lw=1., zorder = 0)\n",
    "        # # draw edge\n",
    "        plt.bar([0, 1, 2, 3], y[i], color=\"none\", edgecolor=\"k\", zorder=2)\n",
    "        ticks = np.arange(0, 36, 5)\n",
    "        plt.yticks(ticks, [str(i) if i % 10 == 0 else \"\" for i in ticks])\n",
    "        plt.xticks(np.arange(4), ['1', '2', '3', '4'])\n",
    "        plt.gca().yaxis.set_label_position(\"right\")\n",
    "        plt.gca().yaxis.tick_right()\n",
    "        plt.xlabel(\"Group\")\n",
    "        plt.ylabel(\"N\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure1_plot(data, post_theta, report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# I got this data by deconstructing the graphs in in Figure 1 of Berry et al 2013.\n",
    "n_i2 = np.array([[10, 10, 10, 10], [15, 15, 15, 15], [20, 20, 20, 20], [20, 20, 25, 25], [20, 20, 30, 30], [20, 20, 35, 35]])\n",
    "y_i2 = np.array([[0, 1, 3, 3], [0, 1, 4, 5], [0, 1, 6, 6], [0, 1, 6, 7], [0, 1, 7, 8], [0, 1, 9, 10]], dtype=np.float64)\n",
    "data2 = np.stack((y_i2, n_i2), axis=2)\n",
    "mu_rule = inla.gauss_rule(201, -7, 1.5)\n",
    "\n",
    "model = inla.binomial_hierarchical()\n",
    "model.log_prior = berry_prior\n",
    "post_theta2, report2 = inla.calc_posterior_theta(model, data2, (mu_rule, sigma2_rule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.linspace(-8, 5, 31)\n",
    "\n",
    "field = np.log10(post_theta2[0]).reshape(report2['theta_grid'].shape[:2])\n",
    "field[np.isnan(field) | np.isinf(field)] = -20\n",
    "plt.title(f\"Posterior PDF from INLA\")\n",
    "plot_field(report2, field, levels=levels, label=\"$\\log_{10}$ (density)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_post, sigma_post = inla.calc_posterior_x(post_theta2, report2)\n",
    "\n",
    "# expit(mu_post) is the posterior estimate of the mean probability.\n",
    "p_post = scipy.special.expit(mu_post)\n",
    "\n",
    "# two sigma confidence intervals transformed from logit to probability space.\n",
    "cilow = scipy.special.expit(mu_post - 2 * sigma_post)\n",
    "cihigh = scipy.special.expit(mu_post + 2 * sigma_post)\n",
    "\n",
    "y = data2[:, :, 0]\n",
    "n = data2[:, :, 1]\n",
    "\n",
    "# The simple ratio of success to samples. Binomial \"p\".\n",
    "raw_ratio = y / n\n",
    "p_success = np.empty_like(mu_post)\n",
    "\n",
    "# early stopping criterion\n",
    "p_success[:5] = 1.0 - scipy.stats.norm.cdf(pmid_x, mu_post[:5], sigma_post[:5])\n",
    "# final success criterion\n",
    "p_success[5] = 1.0 - scipy.stats.norm.cdf(p0_x, mu_post[5], sigma_post[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_post[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_post[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sims = post_theta2.shape[0]\n",
    "n_sigma2 = post_theta2.shape[1]\n",
    "n_mu = post_theta2.shape[2]\n",
    "n_arms = report2[\"x0\"].shape[-1]\n",
    "x_mu = report2[\"x0\"].reshape((n_sims, n_sigma2, n_mu, n_arms))\n",
    "theta_grid = report2['theta_grid']\n",
    "H = report2[\"H\"]\n",
    "x_sigma2 = -(1.0 / H).reshape((n_sims, n_sigma2, n_mu, n_arms))\n",
    "T = (x_mu - mu_post[:, None, None, :]) ** 2 + x_sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12), constrained_layout=True)\n",
    "for i in range(4):\n",
    "    F = T[0, :, :, i] * post_theta2[0, :, :]\n",
    "    cell_volume = mu_rule[1][:, None] * sigma2_rule[1][None, :]\n",
    "    cell_volume = scipy.ndimage.gaussian_filter(cell_volume, 1.0)\n",
    "    plt.subplot(3, 5, 1 + i)\n",
    "    plot_field(\n",
    "        report2,\n",
    "        x_mu[0, :, :, i],\n",
    "        levels=np.linspace(mu_rule[0].min(), mu_rule[0].max(), 21),\n",
    "    )\n",
    "    plt.subplot(3, 5, 6 + i)\n",
    "    plot_field(report2, np.log10(T[0, :, :, i]), levels=np.linspace(-5, 5, 21))\n",
    "    plt.subplot(3, 5, 11 + i)\n",
    "    plt.title(\"Contribution to $\\sigma_{\" + str(i) + \", posterior}$\")\n",
    "    plot_field(report2, np.log10(F * cell_volume), levels=np.linspace(-10, -3, 15))\n",
    "\n",
    "plt.subplot(3, 5, 5)\n",
    "plt.title(\"Posterior PDF\")\n",
    "plot_field(report2, np.log10(post_theta2[0, :]), levels=np.linspace(-8, 3, 23))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure1_plot(data2, post_theta2, report2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness in the marginals\n",
    "\n",
    "Why is the confidence interval on the 0-th arm in the figure above so large? This is a case where one of the core INLA assumptions breaks down. INLA assumes that p(x|y,\\theta) is approximately normal. In this particular case, that assumption is not correct. Intuitively, with 0 successes out of 20 patients, there is a lot more potential for small $x_0$ values than potential for large $x_0$ values. As you can see below, there is substantial skewness. There are approaches to deal with this. See here: https://github.com/mikesklar/kevlar/issues/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_vs = np.linspace(-15, 5, 100)\n",
    "x123_vs = np.full_like(x0_vs, -1.0)\n",
    "x = np.array([x0_vs, x123_vs, x123_vs, x123_vs]).T.copy()\n",
    "lj = model.log_joint(model, x, data[0], np.array([[-1.0, 10.0]]))\n",
    "plt.plot(x0_vs, np.exp(lj))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_post, sigma_post = inla.calc_posterior_x(post_theta2, report2)\n",
    "\n",
    "# expit(mu_post) is the posterior estimate of the mean probability.\n",
    "p_post = scipy.special.expit(mu_post)\n",
    "\n",
    "# two sigma confidence intervals transformed from logit to probability space.\n",
    "cilow = scipy.special.expit(mu_post - 2 * sigma_post)\n",
    "cihigh = scipy.special.expit(mu_post + 2 * sigma_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cilow[0], cihigh[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum = np.sum(np.exp(lj))\n",
    "mean = x0_vs[np.argmax(np.exp(lj))]\n",
    "ci025 = x0_vs[np.argmax(np.cumsum(np.exp(lj)) / total_sum > 0.05)]\n",
    "ci975 = x0_vs[np.argmax(np.cumsum(np.exp(lj)) / total_sum > 0.95)]\n",
    "ci025, ci975, np.abs(mean-ci025), np.abs(mean-ci975), scipy.special.expit(ci025), scipy.special.expit(ci975)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import inla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_gauss_rule(N, a, b):\n",
    "    A = np.log(a)\n",
    "    B = np.log(b)\n",
    "    p, w = inla.gauss_rule(N, a=A, b=B)\n",
    "    pexp = np.exp(p)\n",
    "    wexp = np.exp(p) * w\n",
    "    return (pexp, wexp)\n",
    "\n",
    "a = 1e-8\n",
    "b = 1e3\n",
    "pexp, wexp = log_gauss_rule(90, a, b)\n",
    "alpha = 0.0005\n",
    "beta = 0.000005\n",
    "f = scipy.stats.invgamma.pdf(pexp, alpha, scale=beta)\n",
    "exact = scipy.stats.invgamma.cdf(b, alpha, scale=beta) - scipy.stats.invgamma.cdf(a, alpha, scale=beta)\n",
    "est = np.sum(f * wexp)\n",
    "plt.plot(np.log(pexp) / np.log(10), f)\n",
    "plt.xlabel('$log_{10}\\sigma^2$')\n",
    "plt.ylabel('$PDF$')\n",
    "plt.show()\n",
    "print('exact CDF: ', exact),\n",
    "print('numerical integration CDF: ', est)\n",
    "print('error: ', est - exact)\n",
    "sigma2_rule = (pexp, wexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = np.array([0.05, 0.05, 0.1, 0.2]) # rate of response below this is the null hypothesis\n",
    "p1 = np.array([0.2, 0.2, 0.3, 0.4]) # rate of response above this is the alternative hypothesis.\n",
    "# p0 = np.array([0.1, 0.1, 0.1, 0.1]) # rate of response below this is the null hypothesis\n",
    "# p1 = np.array([0.3, 0.3, 0.3, 0.3]) # rate of response above this is the alternative hypothesis.\n",
    "# rate of response > p0 and < p1 is gray area.\n",
    "p0_x = scipy.special.logit(p0)\n",
    "\n",
    "pmid = (p0 + p1) / 2\n",
    "pmid_x = scipy.special.logit(pmid)\n",
    "\n",
    " # final evaluation criterion \n",
    " # accept the alternative hypo if Pr(p[i] > p0|data) > pfinal_thresh[i]\n",
    "pfinal_thresh = np.array([0.82, 0.82, 0.85, 0.9])\n",
    "\n",
    "# early stopping criteria\n",
    "pmid_accept = 0.9\n",
    "pmid_fail = 0.05\n",
    "\n",
    "prior_mu_mean = scipy.special.logit(0.1)\n",
    "\n",
    "def berry_prior(theta):\n",
    "    mu = theta[..., 0]\n",
    "    mu_prior = scipy.stats.norm.logpdf(mu, prior_mu_mean, 100)\n",
    "\n",
    "    sigma2 = theta[..., 1]\n",
    "    alpha = 0.0005\n",
    "    beta = 0.000005\n",
    "    sigma2_prior = scipy.stats.invgamma.logpdf(sigma2, alpha, scale=beta)\n",
    "    return mu_prior + sigma2_prior\n",
    "\n",
    "model = inla.binomial_hierarchical()\n",
    "model.log_prior = berry_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "\n",
    "def sim(n_sims, N, p):\n",
    "    return np.stack(\n",
    "        (scipy.stats.binom.rvs(N, p, size=(n_sims, 4)), np.full((n_sims, 4), N)), axis=2\n",
    "    )\n",
    "\n",
    "n_sims = 200\n",
    "\n",
    "scenarios = {\n",
    "    \"Null\": [0.05, 0.05, 0.1, 0.2],\n",
    "    \"Alternative\": [0.2, 0.2, 0.3, 0.4],\n",
    "    \"One in the Middle\": [0.2, 0.2, 0.2, 0.5],\n",
    "    \"All in the Middle\": [0.15, 0.15, 0.2, 0.3],\n",
    "    \"One Nugget\": [0.05, 0.05, 0.1, 0.4],\n",
    "    \"2 Null, 2 Alternative\": [0.05, 0.05, 0.3, 0.4],\n",
    "}\n",
    "\n",
    "# Number of patients at the first look.\n",
    "N_0 = 10\n",
    "\n",
    "# Number of patients added per look.\n",
    "deltaN = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "n_looks = 6\n",
    "for k in scenarios:\n",
    "    results[k] = dict(\n",
    "        data=[], mu_post=[], sigma_post=[], p_success=[], success_by_look=[]\n",
    "    )\n",
    "    p = scenarios[k]\n",
    "    data = sim(n_sims, N_0, p)\n",
    "\n",
    "    results[k][\"data\"] = []\n",
    "    success = np.zeros((n_sims, 4), dtype=bool)\n",
    "    stopping_time = np.full((n_sims, 4), -1, dtype=np.int32)\n",
    "    for look in range(n_looks):\n",
    "        results[k][\"data\"].append(data.copy())\n",
    "\n",
    "        mu_rule = inla.gauss_rule(21, -5, 5)\n",
    "        sigma2_rule = log_gauss_rule(21, 1e-7, 1e3)\n",
    "        post_theta, report = inla.calc_posterior_theta(\n",
    "            model, data, (mu_rule, sigma2_rule)\n",
    "        )\n",
    "        mu_post, sigma_post = inla.calc_posterior_x(post_theta, report)\n",
    "        results[k][\"mu_post\"].append(mu_post)\n",
    "        results[k][\"sigma_post\"].append(sigma_post)\n",
    "\n",
    "        if look < 5:\n",
    "            p_success = 1.0 - scipy.stats.norm.cdf(pmid_x, mu_post, sigma_post)\n",
    "            stop_success = 0 * (p_success > pmid_accept) # no early stopping for success\n",
    "            stop_fail = p_success < pmid_fail\n",
    "        else:\n",
    "            p_success = 1.0 - scipy.stats.norm.cdf(p0_x, mu_post, sigma_post)\n",
    "            stop_success = p_success > pfinal_thresh[None, :]\n",
    "            stop_fail = p_success <= pfinal_thresh[None, :]\n",
    "        success[stop_success] = True\n",
    "        stop = stop_success | stop_fail\n",
    "        update_stopping = (stop & (stopping_time == -1)).astype(bool)\n",
    "        stopping_time[update_stopping] = look\n",
    "\n",
    "        results[k][\"p_success\"].append(p_success)\n",
    "        results[k][\"success_by_look\"].append(stop_success)\n",
    "\n",
    "        new_data = sim(n_sims, deltaN, p)\n",
    "        data += new_data\n",
    "    results[k][\"success_by_look\"] = np.array(results[k][\"success_by_look\"])\n",
    "    results[k]['stopping_time'] = stopping_time\n",
    "    results[k]['success'] = success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6), constrained_layout=True)\n",
    "for i, k in enumerate(scenarios):\n",
    "    sample_size = N_0 + results[k]['stopping_time'] * deltaN\n",
    "    mean_sample_size = np.mean(sample_size, axis=0)\n",
    "\n",
    "    plt.subplot(2, 3, 1 + i)\n",
    "    plt.title(k, fontweight='bold')\n",
    "    plt.bar(np.arange(4), mean_sample_size, 0.2, color='gray', )\n",
    "\n",
    "    plt.ylim([0, 35])\n",
    "    plt.yticks(np.arange(0, 36, 5))\n",
    "    plt.ylabel('Pr(Success)')\n",
    "\n",
    "    plt.xticks(np.arange(4), ['1', '2', '3', '4'])\n",
    "    plt.xlabel('Group')\n",
    "\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6), constrained_layout=True)\n",
    "for i, k in enumerate(results):\n",
    "    success = results[k]['success']\n",
    "    n_sims = success.shape[0]\n",
    "    success_rate = success.sum(axis=0) / n_sims\n",
    "    plt.subplot(2, 3, 1 + i)\n",
    "    plt.title(k, fontweight='bold')\n",
    "    plt.bar(np.arange(4), success_rate, 0.2, color='gray', )\n",
    "\n",
    "    plt.ylim([0, 1])\n",
    "    plt.yticks(np.linspace(0, 1, 6))\n",
    "    plt.ylabel('Pr(Success)')\n",
    "\n",
    "    plt.xticks(np.arange(4), ['1', '2', '3', '4'])\n",
    "    plt.xlabel('Group')\n",
    "\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9637099bd81b2ef0895c64d539356b45819bc945d59d426757b1f51ae370d50"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('kevlar')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
