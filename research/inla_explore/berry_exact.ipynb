{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import scipy.stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model and simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match with the INLA notation, the $\\theta$ parameter for Berry et al 2013 is called $x$ here. Also, Berry uses:\n",
    "\\begin{equation}\n",
    "\\tilde{x} = logit(p) - logit(p_1)\n",
    "\\end{equation}\n",
    "whereas we use:\n",
    "\\begin{equation}\n",
    "x = logit(p) = \\tilde{x} + logit(p_1)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = np.full(4, 0.1)  # rate of response below this is the null hypothesis\n",
    "p1 = np.full(4, 0.3)  # rate of response above this is the alternative hypothesis.\n",
    "# rate of response > p0 and < p1 is gray area.\n",
    "p0_theta = scipy.special.logit(p0)\n",
    "\n",
    "pmid = (p0 + p1) / 2\n",
    "pmid_theta = scipy.special.logit(pmid)\n",
    "\n",
    "# final evaluation criterion\n",
    "# accept the alternative hypo if Pr(p[i] > p0|data) > pfinal_thresh[i]\n",
    "pfinal_thresh = np.full(4, 0.85)\n",
    "\n",
    "# early stopping criterion\n",
    "pmid_accept = 0.9\n",
    "pmid_fail = 0.05\n",
    "\n",
    "null_x_berry = np.log(p0 / (1 - p0)) - np.log(p1 / (1 - p1))\n",
    "null_x = np.log(p0 / (1 - p0))\n",
    "prior_mu_mean = null_x[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def berry_prior(theta):\n",
    "    mu = theta[..., 0]\n",
    "    mu_prior = scipy.stats.norm.logpdf(mu, prior_mu_mean, 100)\n",
    "\n",
    "    sigma2 = theta[..., 1]\n",
    "    alpha = 0.0005\n",
    "    beta = 0.000005\n",
    "    sigma2_prior = scipy.stats.invgamma.logpdf(sigma2, alpha, scale=beta)\n",
    "    return mu_prior + sigma2_prior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multidimensional numerical integration\n",
    "\n",
    "We'd like to verify our INLA implementation. MCMC is an alternative that would give a rough verification. However, MCMC converges quite slowly so it's difficult to get nearly exact posterior estimates. Fortunately, the example problem that we are considering here has only six dimensions: two hyperparameters that control the sharing and four latent variables that describe the success of each trial arm. A six dimensional integral is feasible to compute numerically.\n",
    "\n",
    "A fully robust implementation would use adaptive quadrature strategies and cover a much larger parameter domain. However, our goal is not to build a robust multi dimensional integration tool. Instead, our goal is to simply demonstrate that our INLA implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inla\n",
    "\n",
    "# I got this data by deconstructing the graphs in in Figure 1 of Berry et al 2013.\n",
    "n_i = np.array([[i] * 4 for i in [10, 15, 20, 25, 30, 35]])\n",
    "y_i = np.array(\n",
    "    [\n",
    "        [1, 6, 3, 3],\n",
    "        [3, 8, 5, 4],\n",
    "        [6, 9, 7, 5],\n",
    "        [7, 10, 8, 7],\n",
    "        [8, 10, 9, 8],\n",
    "        [11, 11, 10, 9],\n",
    "    ]\n",
    ")\n",
    "n_i = np.array([[10, 10, 10, 10], [15, 15, 15, 15], [20, 20, 20, 20], [20, 20, 25, 25], [20, 20, 30, 30], [20, 20, 35, 35]])\n",
    "y_i = np.array([[0, 1, 3, 3], [0, 1, 4, 5], [0, 1, 6, 6], [0, 1, 6, 7], [0, 1, 7, 8], [0, 1, 9, 10]], dtype=np.float64)\n",
    "data = np.stack((y_i, n_i), axis=2)\n",
    "\n",
    "model = inla.binomial_hierarchical()\n",
    "model.log_prior = berry_prior\n",
    "\n",
    "mu_rule = inla.gauss_rule(41, -5, 3)\n",
    "sigma2_rule = inla.composite_rule(\n",
    "    inla.gauss_rule,\n",
    "    (5, 1e-7, 1e-6),\n",
    "    (5, 1e-6, 1e-5),\n",
    "    (5, 1e-5, 1e-4),\n",
    "    (5, 1e-4, 1e-3),\n",
    "    (5, 1e-3, 1e-2),\n",
    "    (5, 1e-2, 1e-1),\n",
    "    (5, 1e-1, 1e0),\n",
    "    (5, 1e0, 1e1),\n",
    "    (5, 1e1, 1e2),\n",
    "    (5, 1e2, 1e3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MM, SS = np.meshgrid(mu_rule[0], sigma2_rule[0], indexing='ij')\n",
    "theta = np.stack((MM.ravel(), SS.ravel()), axis=1)\n",
    "x0_info = inla.optimize_x0(model, data[:1, None, :], theta[None, :])\n",
    "xcenters = x0_info['x'][0].reshape((mu_rule[0].shape[0], sigma2_rule[0].shape[0], 4))\n",
    "xcenters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstd = np.minimum(np.sqrt(sigma2_rule[0]), np.full_like(sigma2_rule[0], 2.0))\n",
    "xmins = xcenters - 6 * xstd[None, :, None]\n",
    "xmaxs = xcenters + 6 * xstd[None, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 11\n",
    "points, weights = np.polynomial.legendre.leggauss(n)\n",
    "xpts = xmins[None, :, :, :] + (xmaxs[None, :, :, :] - xmins[None, :, :, :]) * (points[:, None, None, None] * 0.5 + 0.5)\n",
    "xwts = weights[None, None, None, :] * (xmaxs[:, :, :, None] - xmins[:, :, :, None]) * 0.5\n",
    "xpts.shape, xwts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = np.transpose(np.array([[\n",
    "    np.meshgrid(*[xpts[:,i,j,k] for k in range(4)], indexing='ij')\n",
    "    for i in range(xpts.shape[1])]\n",
    "    for j in range(xpts.shape[2])\n",
    "]), (2, 3, 4, 5, 6, 1, 0))\n",
    "grids = np.concatenate((\n",
    "    x,\n",
    "    np.broadcast_to(mu_rule[0][None,None,None,None,:,None], x.shape[1:])[None, :],\n",
    "    np.broadcast_to(sigma2_rule[0][None,None,None,None,None,:], x.shape[1:])[None, :]\n",
    "))\n",
    "grids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = np.array(\n",
    "    [\n",
    "        [\n",
    "            xwts[i, j, 0, :, None, None, None]\n",
    "            * xwts[i, j, 1, None, :, None, None]\n",
    "            * xwts[i, j, 2, None, None, :, None]\n",
    "            * xwts[i, j, 3, None, None, None, :]\n",
    "            for i in range(xpts.shape[1])\n",
    "        ]\n",
    "        for j in range(xpts.shape[2])\n",
    "    ]\n",
    ")\n",
    "wts = np.transpose(wts, (2, 3, 4, 5, 1, 0))\n",
    "wts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_grid_x = grids[:4].reshape((4, -1)).T.copy()\n",
    "giant_grid_theta = grids[4:6].reshape((2, -1)).T.copy()\n",
    "joint_density = model.log_joint(model, giant_grid_x, data[0], giant_grid_theta)\n",
    "joint_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma2_rule[0][-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = joint_density.reshape(grids[0].shape)\n",
    "# for i in range(sigma2_rule[0].shape[0]):\n",
    "idx = np.s_[:, 5, 5, 5, 20, -3]\n",
    "plt.plot(grids[0][idx], np.exp(p[idx]), '-*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_sig_marginal = np.sum(\n",
    "    np.exp(joint_density.reshape(grids[0].shape)) * wts,\n",
    "    axis=(0, 1, 2, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_wts = (\n",
    "    wts\n",
    "    * mu_rule[1][None, None, None, None, :, None]\n",
    "    * sigma2_rule[1][None, None, None, None, None, :]\n",
    ")\n",
    "total_integral = np.sum(\n",
    "    np.exp(joint_density.reshape(grids[0].shape)) * total_wts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1 = grids[4][0, 0, 0, 0]\n",
    "grid2 = np.log10(grids[5][0, 0, 0, 0])\n",
    "field = np.log10(mu_sig_marginal / total_integral)\n",
    "field[np.isnan(field) | np.isinf(field)] = -280\n",
    "levels = np.linspace(-8, 5, 31)\n",
    "\n",
    "cntf = plt.contourf(grid1, grid2, field, levels=levels, extend=\"both\")\n",
    "plt.contour(\n",
    "    grid1,\n",
    "    grid2,\n",
    "    field,\n",
    "    colors=\"k\",\n",
    "    linestyles=\"-\",\n",
    "    linewidths=0.5,\n",
    "    levels=levels,\n",
    "    extend=\"both\",\n",
    ")\n",
    "cbar = plt.colorbar(cntf)\n",
    "# cbar.set_label(None)\n",
    "plt.xlabel(\"$\\mu$\")\n",
    "plt.ylabel(\"$\\log_{10} (\\sigma^2)$\")\n",
    "plt.title('Posterior PDF from \"exact\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources of error\n",
    "\n",
    "The goal of developing the \"exact\" integrator was to develop more confidence in our INLA and MCMC estimators. But, first we need to examine the error from this method.\n",
    "\n",
    "There are three sources of error:\n",
    "* $x$ domain error: we arbitrarily truncated the domain in order to numerically integrate. There are other quadrature rules that would handle an infinite domain, but they have their own complexities. Fortunately, we can estimate the quadrature error resulting from the finite domain by evaluating the integrand at the end points of the interval. \n",
    "* approximation error: we chose to use an 11 point quadrature rule in the latent variables. How much more accurate would the integral be if we had chosen a 12 point quadrature rule? Or a 20 point rule? For a smooth integrand, Gaussian quadrature will normally converge very quickly. \n",
    "* $\\theta$ domain error: we truncated the range of sharing hyperparameters. This affects our density function because we need to normalize by the integral over the entire domain of hyperparameters. This $\\theta$ domain error can be made consistent between the different methods we examine by using the same $\\theta$ grid in the INLA calculations. This error is also the easiest form of error to control by a user because it is very obvious when a PDF is still large at the edge of the domain. So, we ignore this source of error. \n",
    "\n",
    "\n",
    "First, we'll examine the $x$ domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_integrate(n_mu, n_sigma2, n_x):\n",
    "    mu_rule = inla.gauss_rule(n_mu, -5, 3)\n",
    "    sigma2_rule = inla.composite_rule(\n",
    "        inla.gauss_rule,\n",
    "        (n_sigma2, 1e-7, 1e-6),\n",
    "        (n_sigma2, 1e-6, 1e-5),\n",
    "        (n_sigma2, 1e-5, 1e-4),\n",
    "        (n_sigma2, 1e-4, 1e-3),\n",
    "        (n_sigma2, 1e-3, 1e-2),\n",
    "        (n_sigma2, 1e-2, 1e-1),\n",
    "        (n_sigma2, 1e-1, 1e0),\n",
    "        (n_sigma2, 1e0, 1e1),\n",
    "        (n_sigma2, 1e1, 1e2),\n",
    "    )\n",
    "    MM, SS = np.meshgrid(mu_rule[0], sigma2_rule[0], indexing='ij')\n",
    "    theta = np.stack((MM.ravel(), SS.ravel()), axis=1)\n",
    "    x0_info = inla.optimize_x0(model, data[:1, None, :], theta[None, :])\n",
    "    xcenters = x0_info['x'][0].reshape((mu_rule[0].shape[0], sigma2_rule[0].shape[0], 4))\n",
    "    xstd = np.minimum(np.sqrt(sigma2_rule[0]), np.full_like(sigma2_rule[0], 2.0))\n",
    "    xmins = xcenters - 3 * xstd[None, :, None]\n",
    "    xmaxs = xcenters + 3 * xstd[None, :, None]\n",
    "\n",
    "    points, weights = np.polynomial.legendre.leggauss(n_x)\n",
    "    xpts = xmins[None, :, :, :] + (xmaxs[None, :, :, :] - xmins[None, :, :, :]) * (points[:, None, None, None] * 0.5 + 0.5)\n",
    "    xwts = weights[None, None, None, :] * (xmaxs[:, :, :, None] - xmins[:, :, :, None]) * 0.5\n",
    "    x = np.transpose(np.array([[\n",
    "        np.meshgrid(*[xpts[:,i,j,k] for k in range(4)], indexing='ij')\n",
    "        for i in range(xpts.shape[1])]\n",
    "        for j in range(xpts.shape[2])\n",
    "    ]), (2, 3, 4, 5, 6, 1, 0))\n",
    "\n",
    "    grids = np.concatenate((\n",
    "        x,\n",
    "        np.broadcast_to(mu_rule[0][None,None,None,None,:,None], x.shape[1:])[None, :],\n",
    "        np.broadcast_to(sigma2_rule[0][None,None,None,None,None,:], x.shape[1:])[None, :]\n",
    "    ))\n",
    "    wts = np.array(\n",
    "        [\n",
    "            [\n",
    "                xwts[i, j, 0, :, None, None, None]\n",
    "                * xwts[i, j, 1, None, :, None, None]\n",
    "                * xwts[i, j, 2, None, None, :, None]\n",
    "                * xwts[i, j, 3, None, None, None, :]\n",
    "                for i in range(xpts.shape[1])\n",
    "            ]\n",
    "            for j in range(xpts.shape[2])\n",
    "        ]\n",
    "    )\n",
    "    wts = np.transpose(wts, (2, 3, 4, 5, 1, 0))\n",
    "\n",
    "    giant_grid_x = grids[:4].reshape((4, -1)).T.copy()\n",
    "    giant_grid_theta = grids[4:6].reshape((2, -1)).T.copy()\n",
    "    joint_density = model.log_joint(model, giant_grid_x, data[0], giant_grid_theta)\n",
    "    total_wts = (\n",
    "        wts\n",
    "        * mu_rule[1][None, None, None, None, :, None]\n",
    "        * sigma2_rule[1][None, None, None, None, None, :]\n",
    "    )\n",
    "\n",
    "    total_integral = np.sum(\n",
    "        np.exp(joint_density.reshape(grids[0].shape)) * total_wts\n",
    "    )\n",
    "    print(np.sum(total_wts))\n",
    "    return total_integral\n",
    "\n",
    "[\n",
    "    exact_integrate(11, 4, n_x)\n",
    "    for n_x in range(5, 20, 2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Is = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Is = np.array(Is)\n",
    "rel_err = np.abs(Is[1:] - Is[:-1]) / np.abs(Is[1:])\n",
    "rel_err"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9637099bd81b2ef0895c64d539356b45819bc945d59d426757b1f51ae370d50"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('kevlar')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
